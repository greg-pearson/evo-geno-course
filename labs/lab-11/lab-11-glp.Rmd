---
output: html_document
---

# Lab 11: Microbiome analysis using dada2 and phyloseq

## dada2 tutorial

### Getting Ready
Load dada2 package
```{r}

library("dada2"); packageVersion("dada2")

```

Load MiSeq SOP data
```{r}

path <- "./data/lab-11-data/MiSeq_SOP"
list.files(path)

```

Read in names of fastq files and perform string manipulation to match lists of forward and reverse fastq files
```{r}

# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

```

### Inspect read quality profiles
#### Visualize quality profile of forward reads
```{r}

plotQualityProfile(fnFs[1:2])

```

Gray-scale is a heat map of the frequency of each quality read score at each base position. Green line is the mean quality score at each position. Orange lines are the quartiles of the quality score distribution. Red line is the scaled proportion of reads that extend to at least that position.

Conclusion: forward reads are good quality reads. The quality profiles do not suggest that any additional trimming is required.

#### Visualize quality profile of reverse reads
```{r}

plotQualityProfile(fnRs[1:2])

```

Note that the reverse reads are significantly worse quality, which is common in Illumina sequencing. Fear not, DADA2 incorporates quality information into its error model. Reverse reads will be truncated at position 160 where quality distribution crashes.

### Filter and Trim

Assign the filenames for the filtered fastq.gz files.
```{r}

# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

```

Set standard filtering parameters: maxN=0, truncQ=2, rm.phix=TRUE, and maxEE=2. maxEE parameter sets the max number of "expected errors" allowed in a read.
```{r}

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)

```

### Learn the Error Rates

The DADA2 algorithm uses a parametric error model. The learnErrors() function learns this error model from the data by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution.
```{r}

errF <- learnErrors(filtFs, multithread=TRUE)

```

```{r}

errR <- learnErrors(filtRs, multithread=TRUE)

```

Visualize the estimated error rates.
```{r}

plotErrors(errF, nominalQ=TRUE)

```

This plot illustrates the error rates for each possible transition. The points are the observed error rates for each consensus quality score. 

### Sample Inference
Apply the core sample inference alogrithm to the filtered and trimmed sequence data.
```{r}

dadaFs <- dada(filtFs, err=errF, multithread=TRUE)

```

```{r}

dadaRs <- dada(filtRs, err=errR, multithread=TRUE)

```

Inspect the returned dada-class object.
```{r}

dadaFs[[1]]

```

Note that the DADA2 algorithm inferred 128 true sequence variants from the 1979 unique sequences. 


### Merge paired reads
Merge the forward and reverese reads together to obtain the full denoised sequences. By default, merged sequences are only output if the forward and reverse reads overlap by at least 12 bases, and are identical to each other in the overlap region.
```{r}

mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])

```

The mergers object is a list of dataframes from each sample. Each dataframe contains the merged sequence, abundance, and indices of the forward and reverse sequence variants. The function mergePairs() removed paired reads that did not overlap, which further reduced spurious output.

### Construct sequence table
Construct an amplicon sequence variant table (ASV) table, which is a higher-resolution version of the OTU table produced by traditional methods, using the makeSequenceTable() function. 
```{r}

seqtab <- makeSequenceTable(mergers)
dim(seqtab)

```

```{r}

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

```

Note that the sequence table is a matrix with rows corresponding to the samples and columns corresponding to the sequence variants. 


### Remove chimeras
Although the core dada method corrects substitution and indel errors, chimeras remain. Identifying chimeric ASVs is simpler following denoising. Chimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant parent sequences. You can remove chimeras by using the function removeBimeraDenovo().
```{r}

seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)

```

Calculate the proportion of sequence variants remaining following chimera removal to total sequence variants.
```{r}

sum(seqtab.nochim)/sum(seqtab)

```

Note that only about 4% of the sequence variants were chimeras that were removed. 

### Track reads through the pipeline
Look at the number of reads that made it through each step in the pipeline.
```{r}

getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)

```

Note that most of the raw reads remain, which is good.

### Assign Taxonomy
The assignTaxonomy() function takes as input a set of sequences to be classified and a training set of reference sequences, and outputs taxonomic assignments with at least minBoot bootstrap confidence.
```{r}

taxa <- assignTaxonomy(seqtab.nochim, "./data/lab-11-data/tax/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)

```

Inspect the taxonomic assignments.
```{r}

taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

```

Note that the Bacteroidetes are well represented among the most abundant taxa in these fecal samples. This makes sense.

Note that few the genus and species were mostly not determined because it is difficult to make those assignments from subsegments of the 16S gene.

### Evaluate Accuracy
Compare and evaluate the sequence variants inferred by DADA2 to the expected composition of the community as reference sequences.
```{r}

unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")

```

```{r}

mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")

```

DADA2 identified 20 ASVs all of which exactly match the reference genomes of the expected community members.

### Bonus: Handoff to phyloseq

Load necessary packages
```{r message=FALSE}

library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")

```

Set theme for all future plots
```{r}

theme_set(theme_bw())

```

Construct a simple sample dataframe from the information encoded in the filenames.
```{r}

samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out

```

Construct phyloseq object directly from the dada2 outputs.
```{r}

ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample

```

Store the DNA sequences of our ASVs in the refseq slot of the phyloseq object, and then rename our taxa to a short string. Renaming taxa to short string is for convenience purposes for tables and visualizations.
```{r}

dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps

```

#### Visualize alpha-diversity
```{r}

plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")

```

Note that there are no obvious systematic difference in alpha-diversity between early and late samples.

#### Visualize Ordinate
```{r}

# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")

```

```{r}

plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")

```

Note that ordination picks out a clear separation between early and late samples.

#### Visualize bar plot

```{r}

top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")

```

Note that nothing jumps out from the taxonomic distribution to explain the early-late difference.

